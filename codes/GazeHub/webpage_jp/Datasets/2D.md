# データセット
このページでは、2D視線推定に関するデータセットの情報を提供しています。

このページでは、

- 各データセットのデータ前処理について紹介します。
- データ前処理のコードを提供します。
- データセットのリンクをまとめます。

私たちのデータ処理コードを使用し、あなたの結果をベンチマークに追加することをお勧めします。

なお、私たちのデータ処理コードを使用する前に、データ整形コード data_processing_core.py をこのページからダウンロードする必要があります。

このページのコードを使用する場合は、以下の論文を引用してください：

```bibtex
@article{Cheng2021Survey,
    title={Appearance-based Gaze Estimation With Deep Learning: A Review and Benchmark},
    author={Yihua Cheng and Haofei Wang and Yiwei Bao and Feng Lu},
    journal={arXiv preprint arXiv:2104.12668},
    year={2021}
}
```

## GazeCapture
### データ前処理
GazeCaptureの評価プロトコルに従います。彼らは既にデータセット全体をトレーニングセット、テストセット、検証セットに分割しています。提供されたアノテーションに基づいて顔と目の画像を切り取ります。切り取った画像のサイズは異なる場合があります。コード内で適切なサイズにリサイズする必要があります。

### 前処理コード
[ここからダウンロード](#)。コードには以下のパラメータが含まれています。

- `root = "/home/cyh/dataset/Original/GazeCapture"`
- `out_root = "/home/cyh/dataset/FaceBased/GazeCapture"`

`root` は元の GazeCapture データセットのパスです。
`out_root` は結果ファイルを保存するパスです。

コードを使用するには、まず2つのパラメータを設定し、次のように実行します：

```bash
python data_processing_gazecapture.py
```

正規化されたデータの使用ガイドも提供しています。

### データセットリンク
[オリジナルデータセットはこちらからダウンロード](#)できます。

このオリジナルデータセットに私たちのコードを適用する場合は、以下を引用してください：

```bibtex
@InProceedings{Krafka_2016_CVPR,
    author = {Krafka, Kyle and Khosla, Aditya and Kellnhofer, Petr and Kannan, Harini and Bhandarkar, Suchendra and Matusik, Wojciech and Torralba, Antonio},
    title = {Eye Tracking for Everyone},
    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2016}
}
```

## MPIIFaceGaze
このデータセットは顔と目の画像を提供し、PoG（Point of Gaze）も提供します。

### データ前処理
元のプロトコルに従ってデータセットを分割します。評価には15名の被験者と各被験者の3000枚の画像を使用します。顔と目の画像を切り取り、MPIIGazeで提供されたPoR（Point of Regard）を直接使用します。

### 前処理コード
`data_processing_mpii.py`
[ここからダウンロード](#)。コードには以下のパラメータが含まれています。

- `root = "/home/cyh/dataset/Original/MPIIFaceGaze"`
- `sample_root = "/home/cyh/dataset/Original/MPIIGaze/Origin/Evaluation Subset/sample list for eye image"`
- `out_root = "/home/cyh/dataset/GazePoint/MPIIGaze"`

`root` は MPIIFaceGaze のパスです。
`sample_root` は MPIIGaze のサンプルリストを示します。このファイルは MPIIFaceGaze には含まれていないため、MPIIGaze からダウンロードする必要があります。
`out_root` は結果ファイルを保存するパスです。

コードを使用するには、まず3つのパラメータを設定し、次のように実行します：

```bash
python data_processing_mpii.py
```

処理されたデータは `out_root` に保存されます。

正規化されたデータの使用ガイドも提供しています。

### データセットリンク
[オリジナルデータセットはこちらからダウンロード](#)できます。

このオリジナルデータセットに私たちのコードを適用する場合は、以下を引用してください：

```bibtex
@inproceedings{zhang2017s,
    title={It’s written all over your face: Full-face appearance-based gaze estimation},
    author={Zhang, Xucong and Sugano, Yusuke and Fritz, Mario and Bulling, Andreas},
    booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on},
    pages={2299--2308},
    year={2017},
    organization={IEEE}
}
```

## EyeDiap
このデータセットは顔と目の画像を提供します。また、PoRも提供しています。

### データ前処理
スクリーンターゲットのVGA動画を選択し、15フレームごとに1枚の画像をサンプリングします。各ビデオのサンプル画像を切り取って同じ数の画像を確保します。各フレームから顔と目の画像を切り取り、提供されたPoRを使用します。ベンチマークでは、全被験者をランダムに4つのクラスタに分け、4回のクロスバリデーションを行います。

### 前処理コード
[ここからダウンロード](#)。コードには以下のパラメータが含まれています。

- `root = "/home/cyh/dataset/Original/EyeDiap/Data"`
- `out_root = "/home/cyh/dataset/EyeBased/EyeDiap"`

`root` は元の EyeDiap データセットのパスです。
`out_root` は結果ファイルを保存するパスです。

コードを使用するには、まず2つのパラメータを設定し、次のように実行します：

```bash
python data_processing_diap.py 
```

正規化されたデータは `out_root` に保存されます。正規化されたデータの使用ガイドも提供しています。

[cluster_diap.pyはこちらからダウンロード](#)。

### データセットリンク
[オリジナルデータセットはこちらからダウンロード](#)できます。

このオリジナルデータセットに私たちのコードを適用する場合は、以下を引用してください：

```bibtex
@inproceedings{eyediap,
    author = {Funes Mora, Kenneth Alberto and Monay, Florent and Odobez, Jean-Marc},
    title = {EYEDIAP: A Database for the Development and Evaluation of Gaze Estimation Algorithms from RGB and RGB-D Cameras},
    year = {2014},
    isbn = {9781450327510},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2578153.2578190},
    doi = {10.1145/2578153.2578190},
    booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications},
    pages = {255–258},
    numpages = {4},
    keywords = {natural-light, database, RGB-D, RGB, remote sensing, gaze estimation, depth, head pose},
    location = {Safety Harbor, Florida},
    series = {ETRA '14}
}
```